{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and download source files\n",
    "# acquire data_info：cve、cwe、fix commit content\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "headers = {'Authorization': 'token'} # API tokens\n",
    "\n",
    "# Tool: Delete txt files starting with the specified number in the specified folder\n",
    "def delete_files_with_prefix(folder_path, prefix_number): \n",
    "    for filename in os.listdir(folder_path):\n",
    "        prefix = f\"{prefix_number}_\"\n",
    "        if filename.startswith(prefix) and filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "# Tool: Remove comments and blank lines from source code to reduce input tokens\n",
    "def remove_comments(language,source_code):\n",
    "    if language == \"python\":\n",
    "        source_code = re.sub(r'(\\'\\'\\'[\\s\\S]*?\\'\\'\\'|\\\"\\\"\\\"[\\s\\S]*?\\\"\\\"\\\")', '', source_code)\n",
    "        source_code = re.sub(r'#.*', '', source_code)\n",
    "        lines = source_code.split('\\n')\n",
    "        non_empty_lines = [line for line in lines if line.strip() != '']\n",
    "        source_code = '\\n'.join(non_empty_lines)\n",
    "    elif language == \"java\":\n",
    "        source_code = re.sub('//.*', '', source_code)*/\n",
    "        source_code = re.sub('/\\*.*?\\*/', '', source_code, flags=re.DOTALL)\n",
    "        source_code = '\\n'.join([line for line in source_code.splitlines() if line.strip()])\n",
    "    # elif language == \"...\": # Can be extended to other languages\n",
    "    return source_code\n",
    "\n",
    "\n",
    "\n",
    "# Switching between using java, python, or other languages\n",
    "language = \"python\" \n",
    "file_extension = \".py\"\n",
    "\n",
    "cve_valuable_lst = []\n",
    "cve_onlyadd_lst = []\n",
    "cve_onelanguage_lst = []\n",
    "\n",
    "# Check if the file has been saved\n",
    "num_save = []\n",
    "folder_path = f\"./data/{language}/{language}_filter/\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    num1 = filename.split(\"_\",1)[0]\n",
    "    if num1 not in num_save:\n",
    "        num_save.append(num1)\n",
    "sorted_num_save = sorted(num_save, key=lambda x: int(x))\n",
    "\n",
    "# If there is enough memory, preload all files first\n",
    "with open(f'./data/nvd_data/nvdcve-1.1-2020.json', 'rb') as f2:\n",
    "    content2 = f2.read()\n",
    "with open(f'./data/nvd_data/nvdcve-1.1-2021.json', 'rb') as f3:\n",
    "    content3 = f3.read()\n",
    "with open(f'./data/nvd_data/nvdcve-1.1-2022.json', 'rb') as f4:\n",
    "    content4 = f4.read()\n",
    "with open(f'./data/nvd_data/nvdcve-1.1-2023.json', 'rb') as f5:\n",
    "    content5 = f5.read()\n",
    "with open(f'./data/nvd_data/nvdcve-1.1-2024.json', 'rb') as f6:\n",
    "    content6 = f6.read()\n",
    "\n",
    "# Read the original REEF file line by line, with one CVE per line\n",
    "num = 0\n",
    "with open(f'./data/REEF_data/query_{language}.jsonl', 'rb') as f1:\n",
    "    for line in f1:\n",
    "        if num >= 0: # Starting from which line, usually set to 0\n",
    "            if num >= 863: # Ending to which line, total: python-863, java-541\n",
    "                break\n",
    "            else:\n",
    "                # skip if the file has already been saved\n",
    "                if str(num) in sorted_num_save:\n",
    "                    num += 1\n",
    "                    continue \n",
    "                else:\n",
    "                    data_info = json.loads(line) \n",
    "        else: # skip below the starting point\n",
    "            num += 1\n",
    "            continue\n",
    "\n",
    "        # Filter vulnerability data from 2020 to 2024\n",
    "        cve = data_info['cve_id']\n",
    "        year = cve.split(\"-\")[1]\n",
    "        if year not in ['2020','2021','2022','2023','2024']: \n",
    "            num += 1\n",
    "            continue\n",
    "\n",
    "        # If there is a duplicate in CVE, skip it\n",
    "        if cve in cve_valuable_lst:\n",
    "            num += 1\n",
    "            continue\n",
    "\n",
    "        # Find the corresponding CVE number from the NVD data for corresponding year\n",
    "        if year == \"2020\":\n",
    "            content = content2\n",
    "        elif year == \"2021\":\n",
    "            content = content3\n",
    "        elif year == \"2022\":\n",
    "            content = content4\n",
    "        elif year == \"2023\":\n",
    "            content = content5\n",
    "        elif year == \"2024\":\n",
    "            content = content6\n",
    "        nvd_cve = json.loads(content)\n",
    "        cve_lst = nvd_cve[\"CVE_Items\"]\n",
    "        for j in cve_lst: \n",
    "            cve_id = j[\"cve\"][\"CVE_data_meta\"][\"ID\"]\n",
    "            if cve_id == cve:\n",
    "                cve_info = j\n",
    "                break\n",
    "\n",
    "        # Remove \"rejected\" vulnerabilities\n",
    "        des = cve_info[\"cve\"][\"description\"][\"description_data\"][0][\"value\"]\n",
    "        if \"Rejected\" in des:\n",
    "            num += 1\n",
    "            continue\n",
    "        cve_valuable_lst.append(cve)\n",
    "\n",
    "        # Filter patches. Rule: Contains suffixes such as'. py ', does not include 'test'\n",
    "        patch_file_list1 = data_info['details']\n",
    "        patch_file_list2 = []\n",
    "        for i in patch_file_list1:\n",
    "            file_string = i['raw_url'].lower()\n",
    "            if file_extension in file_string: \n",
    "                if \"test\" not in file_string:\n",
    "                    patch_file_list2.append(i)\n",
    "\n",
    "        # Skip without files after filtering\n",
    "        if patch_file_list2 == []:\n",
    "            if num not in cve_onelanguage_lst:\n",
    "                cve_onelanguage_lst.append(num)\n",
    "            num += 1\n",
    "            continue\n",
    "\n",
    "        # Download every file in the patch from GitHub\n",
    "        patch_file_list3 = []\n",
    "        wrong_flag1 = 0\n",
    "        for j in range(0,len(patch_file_list2)): \n",
    "            comp = patch_file_list2[j]['raw_url'].split(\"/\")\n",
    "            org =  comp[3] \n",
    "            project = comp[4]\n",
    "            file_path = comp[7].replace(r\"%2F\",\"/\")\n",
    "            url1 = data_info['url']\n",
    "\n",
    "            r1 = \"\"\n",
    "            t1 = 0 \n",
    "            while t1 < 3: \n",
    "                try:\n",
    "                    r1 = requests.get(url1, headers = headers, timeout = 10)\n",
    "                    break\n",
    "                except:\n",
    "                    t1 += 1\n",
    "            if isinstance(r1,str):\n",
    "                print(f'{num}_{j} cannot get commit content')\n",
    "                wrong_flag1 = 1\n",
    "                break\n",
    "            else:\n",
    "                if r1.status_code == 200: # if not exceed GitHub limit\n",
    "                    response_dict1 = r1.json()\n",
    "                    sha2 = response_dict1[\"parents\"][0][\"sha\"] # sha in any parent commit is the same, so just use the first one.\n",
    "\n",
    "                    filename1 = f\"./data/{language}/{language}_source/{num}_{j}@{org}@{project}@{sha2}@{comp[7]}.txt\"\n",
    "                    safe_filename1 = filename1.replace(\"%2F\", \"_\")\n",
    "\n",
    "                    filename2 = f\"./data/{language}/{language}_filter/{num}_{j}@{org}@{project}@{sha2}@{comp[7]}.txt\"\n",
    "                    safe_filename2 = filename2.replace(\"%2F\", \"_\")\n",
    "                    if os.path.exists(safe_filename1): # If it has already been downloaded, skip it and return directly to the file list\n",
    "                        print(f'{num} vul file has downloaded')\n",
    "                        patch_file_list3 = patch_file_list2\n",
    "                        break\n",
    "                    \n",
    "                    vul_file_source = f'https://raw.githubusercontent.com/{org}/{project}/{sha2}/{file_path}'\n",
    "                    file1 = \"\"\n",
    "                    t2 = 0\n",
    "                    while t2 < 3:\n",
    "                        try:\n",
    "                            file1 = requests.get(vul_file_source, headers = headers, timeout = 10)\n",
    "                            break\n",
    "                        except:\n",
    "                            t2 += 1\n",
    "\n",
    "                    if isinstance(file1,str):\n",
    "                        print(f'{num}_{j} cannot get vul file content')\n",
    "                        wrong_flag1 = 1\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        if file1.status_code == 200: # If it's not 200, it means the original version only has the newly added file.\n",
    "                            patch_file_list3.append(patch_file_list2[j]) # final patch file list\n",
    "\n",
    "                            os.makedirs(os.path.dirname(safe_filename1), exist_ok=True)\n",
    "                            with open(safe_filename1,\"wb\") as f2: # save the source file\n",
    "                                f2.write(file1.content)\n",
    "\n",
    "                            file2 = file1.content.decode()\n",
    "                            file2 = remove_comments(language,file2) # Store after removing comments\n",
    "                            file2 = file2.encode()\n",
    "                            os.makedirs(os.path.dirname(safe_filename2), exist_ok=True)\n",
    "                            with open(safe_filename2,\"wb\") as f3: # save the filter file\n",
    "                                f3.write(file2)\n",
    "                        else:\n",
    "                            if num not in cve_onlyadd_lst:\n",
    "                                cve_onlyadd_lst.append(num)\n",
    "                            wrong_flag1 = 1\n",
    "                            break\n",
    "                else:\n",
    "                    print(f'{num}_{j} 3 timeout retries')\n",
    "                    if num not in cve_onlyadd_lst:\n",
    "                        cve_onlyadd_lst.append(num)\n",
    "                    wrong_flag1 = 1                    \n",
    "                    break\n",
    "\n",
    "        if wrong_flag1 == 1: # If any stage fails, delete all stored files\n",
    "            folder_path1 = f\"./data/{language}/{language}_source/\"\n",
    "            delete_files_with_prefix(folder_path1,num)\n",
    "            folder_path2 = f\"./data/{language}/{language}_filter/\"\n",
    "            delete_files_with_prefix(folder_path2,num)\n",
    "            print(f\"delete all files of vul {num}\")\n",
    "            num += 1\n",
    "            continue\n",
    "\n",
    "        num += 1 # next line\n",
    "        \n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
